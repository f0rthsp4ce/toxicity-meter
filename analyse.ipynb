{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTINGS = json.load(open(\"settings.json\"))\n",
    "FORCE_RECOMPUTE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat0 = SETTINGS[\"download\"][\"from_chats\"][0]\n",
    "CHAT0 = pd.read_csv(f\"{chat0}.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "chat1 = SETTINGS[\"download\"][\"from_chats\"][1]\n",
    "CHAT1 = pd.read_csv(f\"{chat1}.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "CHATS = pd.concat([CHAT0, CHAT1])\n",
    "CHAT0_LEN = len(CHAT0)\n",
    "CHAT1_LEN = len(CHAT1)\n",
    "del CHAT0, CHAT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detoxify import Detoxify\n",
    "\n",
    "model1 = Detoxify(\"multilingual\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model2 = pipeline(model=\"SkolkovoInstitute/russian_toxicity_classifier\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model1.predict([\"приветик\", \"как делишки?\"])\n",
    "b = model2([\"приветик\", \"как делишки?\"], return_all_scores=True)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1_predict(x: pd.Series):\n",
    "    BATCH_SIZE = 64\n",
    "    TARGET_KEYS = [\"toxicity\", \"severe_toxicity\", \"identity_attack\", \"insult\", \"threat\"]\n",
    "    scores = np.zeros((len(x),))\n",
    "    for i in range(0, len(x), BATCH_SIZE):\n",
    "        batch = list(x[i : i + BATCH_SIZE])\n",
    "        pred = model1.predict(list(batch))\n",
    "        pred_filtered = np.array([pred[key] for key in TARGET_KEYS])\n",
    "        batch_scores = np.max(pred_filtered, axis=0)\n",
    "        scores[i : i + BATCH_SIZE] = batch_scores\n",
    "    return scores\n",
    "\n",
    "\n",
    "model1_predict(pd.Series([\"приветик\", \"как делишки?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2_predict(x: pd.Series):\n",
    "    return [\n",
    "        next(row[\"score\"] for row in verdict if row[\"label\"] == \"toxic\")  # type: ignore\n",
    "        for verdict in model2(list(x), top_k=None, truncation=True)  # type: ignore\n",
    "    ]\n",
    "\n",
    "\n",
    "model2_predict(pd.Series([\"приветик\", \"как делишки?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(f\"chats.parquet\") or FORCE_RECOMPUTE:\n",
    "    CHATS[\"toxicity_1\"] = model1_predict(CHATS[\"message\"])\n",
    "    CHATS[\"toxicity_2\"] = model2_predict(CHATS[\"message\"])\n",
    "    CHATS.to_parquet(f\"chats.parquet\")\n",
    "else:\n",
    "    CHATS = pd.read_parquet(f\"chats.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group toxicity by day (take max)\n",
    "from functools import partial\n",
    "\n",
    "q = partial(np.quantile, q=0.95)\n",
    "\n",
    "by_day = CHATS.groupby(CHATS[\"date\"].dt.date)\n",
    "# by_day.agg({\"toxicity_1\": \"max\", \"toxicity_2\": \"max\"}).plot()\n",
    "by_day.agg({\"toxicity_1\": q, \"toxicity_2\": q}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group toxocity by from_id\n",
    "\n",
    "q = partial(np.percentile, q=95)\n",
    "\n",
    "by_from_id = CHATS.groupby(\"from_id\")\n",
    "agg = by_from_id.agg({\"toxicity_1\": q, \"toxicity_2\": q})\n",
    "\n",
    "agg_1 = agg.sort_values(\"toxicity_1\", ascending=False)\n",
    "ax = agg_1.plot.bar()\n",
    "# ax.set_xticklabels(\n",
    "#     [\"King\", \"Queen\", \"Joker\"] + [\"███\" for _ in range(len(ax.get_xticks()) - 3)]\n",
    "# )\n",
    "ax.plot()\n",
    "\n",
    "agg_2 = agg.sort_values(\"toxicity_2\", ascending=False)\n",
    "ax = agg_2.plot.bar()\n",
    "# ax.set_xticklabels(\n",
    "#     [\"King\", \"Queen\", \"Joker\"] + [\"███\" for _ in range(len(ax.get_xticks()) - 3)]\n",
    "# )\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_from_id.aggregate({\"toxicity_1\": \"mean\", \"toxicity_2\": \"mean\"}).sort_values(\n",
    "#     \"toxicity_1\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_ids = set(CHATS[\"from_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if exists\n",
    "if not os.path.exists(f\"id2username.parquet\") or FORCE_RECOMPUTE:\n",
    "    import telethon\n",
    "\n",
    "    from_usernames = []\n",
    "    async with telethon.TelegramClient(\n",
    "        telethon.sessions.StringSession(os.environ[\"TELEGRAM_SESSION_TELETHON\"]),\n",
    "        int(os.environ[\"TELEGRAM_API_ID\"]),\n",
    "        os.environ[\"TELEGRAM_API_HASH\"],\n",
    "    ) as tg:\n",
    "        await tg.get_messages(chat0, limit=CHAT0_LEN)\n",
    "        await tg.get_messages(chat1, limit=CHAT1_LEN)\n",
    "        for id in from_ids:\n",
    "            user = await tg.get_entity(id)\n",
    "            username = user.username or user.first_name\n",
    "            from_usernames.append(username)\n",
    "\n",
    "    id2username = pd.DataFrame({\"id\": list(from_ids), \"username\": from_usernames})\n",
    "    id2username.to_parquet(f\"id2username.parquet\")\n",
    "else:\n",
    "    id2username = pd.read_parquet(f\"id2username.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(agg_1, id2username, left_on=\"from_id\", right_on=\"id\").iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(agg_2, id2username, left_on=\"from_id\", right_on=\"id\").iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATS[[\"toxicity_1\", \"toxicity_2\"]].corr().iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = CHATS[[\"toxicity_1\", \"toxicity_2\"]].quantile(0.995)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATS[(CHATS[[\"toxicity_1\", \"toxicity_2\"]] > Q).max(axis=1)][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
